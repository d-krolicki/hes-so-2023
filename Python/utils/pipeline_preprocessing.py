import sys
sys.path.append("/OLD-DATA-STOR/HESSO_Internship_2023/Dariusz")
import SimpleITK as sitk
import os
import numpy as np
import shutil
import logging
import json
import time
import re

from typing import Tuple, List, Dict, Optional
from fuzzywuzzy import fuzz

from Python.utils.utils import extract_diseases_in_image, get_empty_classes_dict

logging.basicConfig(level=logging.INFO)
ch = logging.StreamHandler()
formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s",
                              "%Y-%m-%d %H:%M:%S")
ch.setFormatter(formatter)

SOURCE_FOLDER = "/OLD-DATA-STOR/segmentation ovud"


def extract_file_pairs(source_folder:str):

    ldir = sorted(os.listdir(source_folder))

    images = []
    labels = []
    for filename in ldir:
        if filename.startswith("."):
            continue
        elif filename.endswith(".mha") and os.path.splitext(filename)[0]+".seg.nrrd" in ldir:   # if the file is an image, and has a corresponding label
            images.append(os.path.join(source_folder, filename))
        elif filename.endswith(".seg.nrrd") and os.path.splitext(os.path.splitext(filename)[0])[0]+".mha" in ldir:  # if the file is a label, and has a corresponding image
            labels.append(os.path.join(source_folder, filename))
        else:
            continue
    return images, labels


def check_for_file_corruptions(images:List, labels:List, image_save_dir:str, segmentation_save_dir:str):

    logger = logging.getLogger("check_for_file_corruptions")
    logger.addHandler(ch)
    logger.propagate = False

    if len(images) != len(labels):
        raise RuntimeError(f"The amount of found images is not equal to the amount of found labels.")
    l = len(images)
    for i, (image_path, label_path) in enumerate(zip(images, labels)):
        
        sys.stdout.write(f"\rAnalyzing file {i+1} of {l}")
        sys.stdout.flush()
        try:
            try:
                image = load_image(image_path)[0]
                save_image(image, filepath=os.path.join(image_save_dir, os.path.split(image_path)[1]))
                
            except:
                logger.warning(f"Encountered problem with file {image_path}")
                logger.warning(f"It is likely due to file corruption or unexpected EOF.")
                logger.warning(f"Omitting the file and proceeding with further analysis.")
                images.remove(image_path)
                labels.remove(label_path)
                continue

            try:
                label = load_label(label_path)[0]
                save_label(label, filepath=os.path.join(segmentation_save_dir, os.path.split(label_path)[1]))

            except:
                logger.warning(f"Encountered problem with file {label_path}")
                logger.warning(f"It is likely due to file corruption or unexpected EOF.")
                logger.warning(f"Omitting the file and proceeding with further analysis.")
                images.remove(image_path)
                labels.remove(label_path)
        except:
            continue
    im, la = [], []
    for i, (image_path, label_path) in enumerate(zip(images, labels)):
        im.append(os.path.join(image_save_dir, os.path.split(image_path)[1]))
        la.append(os.path.join(segmentation_save_dir, os.path.split(label_path)[1]))
    return im, la


def encode_lesions(source_folder_path:str) -> Dict[str, int]:
    """
    Assigns unique integer labels to lesions.

    Parameters
    --------
    source_folder_path : str
        Path to the root of the data folder.

    Returns
    -------
    dct : Dict[str, int]
        Dictionary of lesions paired with integer labels.
    """
    dct = {}
    for i, key in enumerate(get_empty_classes_dict(source_folder_path).keys()):
        dct[key] = i
    
    return dct


def merge_classes(
        encoded_lesions:Dict[str, int],
        classes:list, 
        custom_classes:Optional[list]=None,
        keywords:Optional[list]=None
        ) ->Tuple[Dict[str, int], Dict[str, str], Dict[str, int]]:
    """
    Carries out a class merge. 
    
    Merging classes is useful in multi-label, multi-class segmentation, for more general segmentation.
    Each of custom_classes is a class added to the dataset, composed from different classes already present.
    The classes are merged depending on whether the passed keyword matches the name of a certain class.
    For example, passing a keyword "node" would match classes like "sternal lymph node", "axillary lymph node" etc.

    Parameters
    --------
    encoded_lesions : str
        Dictionary of lesions with assigned integer labels, generated by the encode_lesions() function.
    classes : list
        List of already present classes to be chosen from the dataset.
    custom_classes : list
        List of custom classes to be created.
    keywords : list
        List of keywords used to merge classes.
    
    Returns
    -------
    classes_to_labels : Dict[str, int]
        Dictionary of classes paired with their respective integer encodings. Contains both original and custom classes.
    keywords_to_custom_classes : Dict[str, str]
        Dictionary of keywords to custom classes paired with those custom classes.
    classes_to_channels : Dict[str, int]
        Dictionary of classes paired with their respective channels in segmentation.
    """
    logger = logging.getLogger("merge_classes")
    logger.addHandler(ch)
    logger.propagate = False

    if custom_classes:
        logger.info(f" Beginning class merge. Found {len(custom_classes)} custom classes.")
    classes_to_labels = {}
    
    for key in encoded_lesions.keys():
        if key in classes:
            classes_to_labels[key] = encoded_lesions[key]

    if not custom_classes and keywords:
        raise TypeError(" No custom classes were provided, but keywords regarding merging are present. Please remove unnecessary keywords, or provide custom classes.")
    elif custom_classes and not keywords:
        raise TypeError(" Custom classes are present, but no keywords regarding merging were provided. Please provide appropiate keywords.")
    elif custom_classes and keywords and len(custom_classes) == len(keywords):
        for j, custom_class in enumerate(custom_classes):
            classes_to_labels[custom_class] = max(encoded_lesions.values()) + 1
    
    keywords_to_custom_classes = {}
    if custom_classes:
        logger.info(f" Class merge completed.")
        for i in range(len(custom_classes)):
            keywords_to_custom_classes[keywords[i]] = custom_classes[i]
    
    classes_to_channels = {}
    for i, c in enumerate(classes):
        classes_to_channels[c] = i

    return classes_to_labels, keywords_to_custom_classes, classes_to_channels


def load_image(path:str):

    reader = sitk.ImageFileReader()
    reader.SetImageIO("MetaImageIO")
    reader.SetFileName(path)
    
    image = reader.Execute()

    img_name = os.path.split(path)[1]
    return image, img_name


def load_label(path:str):

    reader = sitk.ImageFileReader()
    reader.SetImageIO("NrrdImageIO")
    reader.SetFileName(path)
    
    label = reader.Execute()

    label_name = os.path.split(path)[1]
    return label, label_name


def save_image(image:sitk.Image, filepath:str):
    
    writer = sitk.ImageFileWriter()
    writer.UseCompressionOn()
    writer.SetImageIO("MetaImageIO")
    writer.SetFileName(filepath)
    writer.Execute(image)

    return


def save_label(label:sitk.Image, filepath:str):

    writer = sitk.ImageFileWriter()
    writer.UseCompressionOn()
    writer.SetImageIO("NrrdImageIO")
    writer.SetFileName(filepath)
    writer.Execute(label)

    return


def load_json(filepath:str):

    f = open(filepath, "r")
    dct = json.load(f)
    f.close()
    return dct


def correct_typos_in_lesions(label:sitk.Image, label_save_dir:str, classes:List[str]):

    for k in label.GetMetaDataKeys():
        if re.match(r'^Segment\d_Name$', k):
            for c in classes:
                score = fuzz.ratio(label.GetMetaData(k), c)
                if score > 90:
                    label[k] = c

    save_label(label, label_save_dir)

    return label


def create_info_json(
        label:sitk.Image,
        label_name:str, 
        merged_classes:Dict[str, int],
        keywords_to_custom_classes:Optional[Dict[str, str]],
        encoded_lesions:Dict[str, int],
        json_dir:str
        ):
    
    dct = {"lesions": {}}
    j = 1

    for k in label.GetMetaDataKeys():
        if re.match(r'^Segment\d_Name$', k):
            if label.GetMetaData(k) in merged_classes.keys():
                dct['lesions'][label.GetMetaData(k)] = (j, encoded_lesions[label.GetMetaData(k)])   # tuple(label_in_segmentation, global_label - from encoded_lesions)
            j += 1
    last_found_label_value = 0
    for key in label.GetMetaDataKeys():
        for k in keywords_to_custom_classes.keys():
            if re.match(r'^Segment\d_Name$', key):
                last_found_label_value += 1
            if re.findall(r"\b" + k + r"\b", label.GetMetaData(key)):
                    dct['lesions'][keywords_to_custom_classes[k]] = (last_found_label_value, 
                                                                     merged_classes[keywords_to_custom_classes[k]])
    json_string = json.dumps(dct)

    filename = os.path.splitext(os.path.splitext(label_name)[0])[0] + ".json"
    with open(os.path.join(json_dir, filename), "w+") as f:
        f.write(json_string)
        f.close()


def prepare_segmentation_masks(
        image, 
        label, 
        filename, 
        json_folder, 
        label_folder, 
        classes_to_channels, 
        custom_classes, 
        spacing, 
        unit_spacing=False
        ):
    
    if image.GetSize() == label.GetSize():
        seg_arr = sitk.GetArrayFromImage(label)
        filename_noext = os.path.splitext(os.path.splitext(filename)[0])[0]
        jsonfile = open(os.path.join(json_folder, filename_noext+".json"), 'r')
        seg_json = json.load(jsonfile)

        # if not os.path.exists(os.path.join(label_folder, filename_noext)):
        #     os.mkdir(os.path.join(label_folder, filename_noext))

        writer = sitk.ImageFileWriter()
        writer.SetImageIO("NrrdImageIO")
        writer.UseCompressionOn()
        
        for k, v in classes_to_channels.items():
            arr = np.zeros(seg_arr.shape)
            for k1, v1 in seg_json['lesions'].items():
                if k == k1:
                    arr = np.array((seg_arr==v1[0]).astype(int))
            img = sitk.GetImageFromArray(arr)
            img.SetSpacing(image.GetSpacing())
            img.SetOrigin(image.GetOrigin())
            img.SetDirection(image.GetDirection())

            if unit_spacing:
                original_image_spacing = image.GetSpacing()
                original_image_size = image.GetSize()

                new_size = [int(round(osz*ospc/nspc)) for osz,ospc,nspc in zip(original_image_size, original_image_spacing, spacing)]

                img = sitk.Resample(
                    img,
                    new_size,
                    sitk.Transform(),
                    sitk.sitkNearestNeighbor,
                    img.GetOrigin(),
                    (1.0,1.0,1.0),
                    img.GetDirection(),
                    0,
                    img.GetPixelID()
                )

                # if not os.path.exists(os.path.join(
                #     "/OLD-DATA-STOR/HESSO_Internship_2023/Dariusz/Data/unified-spacing/labels",
                #     filename_noext
                # )):
                #     os.mkdir(os.path.join(
                #         "/OLD-DATA-STOR/HESSO_Internship_2023/Dariusz/Data/unified-spacing/labels",
                #         filename_noext)
                #     )
                print(img.GetSize(), img.GetDirection())
                sitk.WriteImage(
                    image = img,
                    fileName = os.path.join(
                    label_folder,
                    filename_noext,
                    "Channel"+str(v)+".seg.nrrd"
                    ),
                    useCompression=True
                )
            else:    
                print(img.GetSize(), img.GetDirection())
                writer.SetFileName(os.path.join(label_folder, filename_noext, "Channel"+str(v)+".seg.nrrd"))
                writer.Execute(img)
        
        next_channel_index = len(classes_to_channels)

        for custom_class in custom_classes:
            arr = np.zeros(seg_arr.shape)
            for k1, v1 in seg_json['lesions'].items():
                if custom_class == k1:
                    arr = np.array((seg_arr==v1[0]).astype(int))
            img = sitk.GetImageFromArray(arr)
            img.SetSpacing(image.GetSpacing())
            img.SetOrigin(image.GetOrigin())
            img.SetDirection(image.GetDirection())

            if unit_spacing:
                img = sitk.Resample(
                    img,
                    new_size,
                    sitk.Transform(),
                    sitk.sitkNearestNeighbor,
                    img.GetOrigin(),
                    (1.0,1.0,1.0),
                    img.GetDirection(),
                    0,
                    img.GetPixelID()
                )

                # if not os.path.exists(os.path.join(
                #     "/OLD-DATA-STOR/HESSO_Internship_2023/Dariusz/Data/unified-spacing/labels",
                #     filename_noext
                # )):
                #     os.mkdir(os.path.join(
                #         "/OLD-DATA-STOR/HESSO_Internship_2023/Dariusz/Data/unified-spacing/labels",
                #         filename_noext)
                #     )
                print(img.GetSize(), img.GetDirection())
                sitk.WriteImage(
                    image = img,
                    fileName = os.path.join(
                    label_folder,
                    filename_noext,
                    "Channel"+str(next_channel_index)+".seg.nrrd"
                    ),
                    useCompression=True
                )
            else:
                print(img.GetSize(), img.GetDirection())
                writer.SetFileName(os.path.join(label_folder, filename_noext, "Channel"+str(next_channel_index)+".seg.nrrd"))
                writer.Execute(img)
    else:
        seg_arr = sitk.GetArrayFromImage(image)
        filename_noext = os.path.splitext(os.path.splitext(filename)[0])[0]
        jsonfile = open(os.path.join(json_folder, filename_noext+".json"), 'r')
        seg_json = json.load(jsonfile)

        original_image_spacing = image.GetSpacing()
        original_image_size = image.GetSize()

        new_size = [int(round(osz*ospc/nspc)) for osz,ospc,nspc in zip(original_image_size, original_image_spacing, spacing)]

        if not os.path.exists(os.path.join(label_folder, filename_noext)):
            os.mkdir(os.path.join(label_folder, filename_noext))

        writer = sitk.ImageFileWriter()
        writer.SetImageIO("NrrdImageIO")
        writer.UseCompressionOn()
        for k, v in classes_to_channels.items():
            arr = np.zeros(seg_arr.shape)
            img = sitk.GetImageFromArray(arr)
            img.SetSpacing(image.GetSpacing())
            img.SetOrigin(image.GetOrigin())
            img.SetDirection(image.GetDirection())

            if unit_spacing:
                img = sitk.Resample(
                    img,
                    new_size,
                    sitk.Transform(),
                    sitk.sitkNearestNeighbor,
                    img.GetOrigin(),
                    (1.0,1.0,1.0),
                    img.GetDirection(),
                    0,
                    img.GetPixelID()
                )
                print(img.GetSize(), img.GetDirection())
                sitk.WriteImage(
                    image = img,
                    fileName = os.path.join(
                    label_folder,
                    filename_noext,
                    "Channel"+str(v)+".seg.nrrd"
                    ),
                    useCompression=True
                )
            else:    
                print(img.GetSize(), img.GetDirection())
                writer.SetFileName(os.path.join(label_folder, filename_noext, "Channel"+str(v)+".seg.nrrd"))
                writer.Execute(img)
        
        next_channel_index = len(classes_to_channels)

        for custom_class in custom_classes:
            arr = np.zeros(seg_arr.shape)
            img = sitk.GetImageFromArray(arr)
            img.SetSpacing(image.GetSpacing())
            img.SetOrigin(image.GetOrigin())
            img.SetDirection(image.GetDirection())

            if unit_spacing:
                img = sitk.Resample(
                    img,
                    new_size,
                    sitk.Transform(),
                    sitk.sitkNearestNeighbor,
                    img.GetOrigin(),
                    (1.0,1.0,1.0),
                    img.GetDirection(),
                    0,
                    img.GetPixelID()
                )
                print(img.GetSize(), img.GetDirection())
                sitk.WriteImage(
                    image = img,
                    fileName = os.path.join(
                    label_folder,
                    filename_noext,
                    "Channel"+str(next_channel_index)+".seg.nrrd"
                    ),
                    useCompression=True
                )
            else:
                print(img.GetSize(), img.GetDirection())
                writer.SetFileName(os.path.join(label_folder, filename_noext, "Channel"+str(next_channel_index)+".seg.nrrd"))
                writer.Execute(img)

        
        

def get_encoded_lesions_from_json(json_dir):

    encoded_lesions = {}
    for filename in os.listdir(json_dir):
        f = open(os.path.join(json_dir, filename), "r")
        dct = json.load(f)['lesions']
        for k, v in dct.items():
            encoded_lesions[k] = v[1]
        f.close()
    return encoded_lesions